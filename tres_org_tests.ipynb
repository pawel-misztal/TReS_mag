{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069e291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HSA_OVERRIDE_GFX_VERSION'] = '10.3.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0594e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a756e390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  torch.Size([1, 32, 64])\n",
      "msa output shape:  torch.Size([1, 32, 64])\n",
      "ffn output shape:  torch.Size([1, 32, 64])\n",
      "transformer output shape:  torch.Size([1, 32, 64])\n"
     ]
    }
   ],
   "source": [
    "import tres.impl_at1 as tres\n",
    "import torch\n",
    "\n",
    "\n",
    "mhsa = tres.MultiHeadSelfAttentionBlock()\n",
    "ffn = tres.FeedForwardNetworkBlock()\n",
    "trans = tres.TransformerBlock()\n",
    "\n",
    "#zakładamy że jest to już po flatten\n",
    "testData = torch.rand((1,32,64))\n",
    "\n",
    "\n",
    "print(\"input shape: \", testData.shape)\n",
    "\n",
    "omsa = mhsa.forward(testData)\n",
    "\n",
    "print(\"msa output shape: \", omsa.shape)\n",
    "\n",
    "offn = ffn.forward(omsa)\n",
    "\n",
    "print(\"ffn output shape: \", offn.shape)\n",
    "\n",
    "otrans = trans.forward(testData)\n",
    "\n",
    "print(\"transformer output shape: \", otrans.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b3a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "def printModelData(model):\n",
    "  print(summary(\n",
    "    model=model,\n",
    "    input_size=(1,3,224,224),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    row_settings=['var_names']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46af2790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "ap = nn.AdaptiveAvgPool2d((7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd6baacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrpaw/.local/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Datasets.CLIVEDataset import CLIVEDataset, CLIVE_PATH\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "trans = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(0.5),\n",
    "    v2.RandomVerticalFlip(0.5),\n",
    "    v2.RandomCrop((224,224)),\n",
    "    # v2.Resize((224,224)),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225))\n",
    "])\n",
    "transTest = v2.Compose([\n",
    "    v2.Resize((224,224)),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225))\n",
    "])\n",
    "transTest2 = v2.Compose([\n",
    "    v2.RandomCrop((224,224)),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225))\n",
    "])\n",
    "\n",
    "\n",
    "trainDataset = CLIVEDataset(CLIVE_PATH, True,trans)\n",
    "testDataset = CLIVEDataset(CLIVE_PATH, False,transTest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0926646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5337e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "trainDataLoader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True,num_workers=2)\n",
    "testDataLoader = DataLoader(testDataset, batch_size=batch_size, shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb184ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "cpu = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "073cdb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maghelper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrpaw/Documents/Projects/Python/PytorchTestRocm/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from helpersmag.trainer import trainLoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b62e1ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "tensor(2.6400)\n",
      "tensor(-2.1179)\n",
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imgs1, lbls1 = next(iter(trainDataLoader))\n",
    "print(imgs1.shape)\n",
    "print(imgs1.max())\n",
    "print(imgs1.min())\n",
    "print(lbls1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1282fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.data_loader as data_loader\n",
    "import org.posencode as posencode\n",
    "\n",
    "class Conf:\n",
    "    datapath = \"/home/mrpaw/Documents/mag_databases/LIVEC_or_CLIVE/ChallengeDB_release/ChallengeDB_release\"\n",
    "    dataset = \"clive\"\n",
    "    seed = 2021\n",
    "    svpath = \"save\"\n",
    "    train_patch_num = 20#50 #ilość losowych paczy na batch\n",
    "    test_patch_num = 20#50 #ilość losowych paczy na batch\n",
    "    lr = 2e-5\n",
    "    weight_decay = 5e-4\n",
    "    batch_size = 10\n",
    "    epochs = 1#3\n",
    "    vesion = 1\n",
    "    patch_size = 224\n",
    "    droplr = 0 #1\n",
    "    gpunum = 0\n",
    "    network = 'resnet50'\n",
    "    nheadt = 16\n",
    "    num_encoder_layerst = 2\n",
    "    dim_feedforwardt = 64\n",
    "\n",
    "config = Conf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d51dffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "folder_path = {\n",
    "    'live':     config.datapath,\n",
    "    'csiq':     config.datapath,\n",
    "    'tid2013':  config.datapath,\n",
    "    'kadid10k': config.datapath,\n",
    "    'clive':    config.datapath,\n",
    "    'koniq':    config.datapath,\n",
    "    'fblive':   config.datapath,\n",
    "    }\n",
    "\n",
    "img_num = {\n",
    "    'live':     list(range(0, 29)),\n",
    "    'csiq':     list(range(0, 30)),\n",
    "    'kadid10k': list(range(0, 80)),\n",
    "    'tid2013':  list(range(0, 25)),\n",
    "    'clive':    list(range(0, 1162)),\n",
    "    'koniq':    list(range(0, 10073)),\n",
    "    'fblive':   list(range(0, 39810)),\n",
    "    }\n",
    "\n",
    "total_num_images = img_num[config.dataset]\n",
    "\n",
    "\n",
    "# Randomly select 80% images for training and the rest for testing\n",
    "random.shuffle(total_num_images)\n",
    "train_index = total_num_images[0:int(round(0.8 * len(total_num_images)))]\n",
    "test_index = total_num_images[int(round(0.8 * len(total_num_images))):len(total_num_images)]\n",
    "train_idx = train_index\n",
    "test_idx= test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f73a67e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "datapath = folder_path[config.dataset]\n",
    "\n",
    "train_loader = data_loader.DataLoader(config.dataset, datapath, \n",
    "\t\t\t\t\t\t\t\t\t\t\t  train_idx, config.patch_size, \n",
    "\t\t\t\t\t\t\t\t\t\t\t  config.train_patch_num, \n",
    "\t\t\t\t\t\t\t\t\t\t\t  batch_size=config.batch_size, istrain=True)\n",
    "\t\t\n",
    "test_loader = data_loader.DataLoader(config.dataset, datapath,\n",
    "                                        test_idx, config.patch_size,\n",
    "                                        config.test_patch_num, istrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "180e0f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 224, 224])\n",
      "tensor(2.6400)\n",
      "tensor(-2.1179)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "tensor(2.6400)\n",
      "tensor(-2.0323)\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataLoader1 = train_loader.get_data()\n",
    "testDataLoader1 = test_loader.get_data()\n",
    "\n",
    "imgs, lbls = next(iter(trainDataLoader1))\n",
    "print(imgs.shape)\n",
    "print(imgs.max())\n",
    "print(imgs.min())\n",
    "print(lbls.shape)\n",
    "\n",
    "timgs, tlbls = next(iter(testDataLoader1))\n",
    "print(timgs.shape)\n",
    "print(timgs.max())\n",
    "print(timgs.min())\n",
    "print(tlbls.shape)\n",
    "tlbls.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f9c11c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1860 4640\n",
      "930 232\n"
     ]
    }
   ],
   "source": [
    "print(trainDataLoader1.__len__(), testDataLoader1.__len__())\n",
    "print(len(train_idx), len(test_idx))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83498120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from org.models import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d483e259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrpaw/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mrpaw/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Net(config, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba597b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputImg = imgs[0].unsqueeze(0)\n",
    "inputImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b2b5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "inputImg = inputImg.cuda()\n",
    "\n",
    "res = model.forward(inputImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c364b902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, tuple)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res), type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd79cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, consistLoss = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eba2dce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "919f1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42ba76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lossFn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4977a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46a86600",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95c66b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "345ffd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training... 4650/4650, lr nn, Avg Loss: 7.5796, SRCC: 0.8465, PLCC: 0.8595, MAE: 7.5780, COS: 0.9835\t\t\t\t\t\t\n",
      "  Testing... 11600/11600, Avg Loss: 23.1612, SRCC: 0.7156, PLCC: 0.7727, MAE: 23.1592, COS: 0.9806\t\t\t\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [35:15<00:00, 2115.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best acc  0.7155806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainLoop(model, trainDataLoader1, testDataLoader1, optimizer, lossFn, steps, 'cuda', save=False)\n",
    "# trainLoop(model, trainDataLoader, testDataLoader, optimizer, lossFn, steps, device, lrScheluder,scheluderStepsPerEpoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75e65cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "import copy\n",
    "import json\n",
    "from typing import Optional, List\n",
    "\n",
    "import org.data_loader as data_loader\n",
    "from org.transformers import Transformer\n",
    "from org.posencode import PositionEmbeddingSine\n",
    "\n",
    "class TReS(object):\n",
    "\t\n",
    "\tdef __init__(self, config, device,  svPath, datapath, train_idx, test_idx,Net, model = None):\n",
    "\t\tsuper(TReS, self).__init__()\n",
    "\t\t\n",
    "\t\tself.device = device\n",
    "\t\tself.epochs = config.epochs\n",
    "\t\tself.test_patch_num = config.test_patch_num\n",
    "\t\tself.l1_loss = torch.nn.L1Loss()\n",
    "\t\tself.lr = 2e-5\n",
    "\t\tself.lrratio = 10\n",
    "\t\tself.weight_decay = config.weight_decay\n",
    "\t\tself.net = Net(config,device).to(device) if model == None else model\n",
    "\t\tself.droplr = config.droplr\n",
    "\t\tself.config = config\n",
    "\t\tself.clsloss =  nn.CrossEntropyLoss()\n",
    "\t\tself.paras = [{'params': self.net.parameters(), 'lr': self.lr} ]\n",
    "\t\tself.solver = torch.optim.Adam(self.paras, weight_decay=self.weight_decay)\n",
    "\n",
    "\n",
    "\t\ttrain_loader = data_loader.DataLoader(config.dataset, datapath, \n",
    "\t\t\t\t\t\t\t\t\t\t\t  train_idx, config.patch_size, \n",
    "\t\t\t\t\t\t\t\t\t\t\t  config.train_patch_num, \n",
    "\t\t\t\t\t\t\t\t\t\t\t  batch_size=config.batch_size, istrain=True)\n",
    "\t\t\n",
    "\t\ttest_loader = data_loader.DataLoader(config.dataset, datapath,\n",
    "\t\t\t\t\t\t\t\t\t\t\t test_idx, config.patch_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\t config.test_patch_num, istrain=False)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tself.train_data = train_loader.get_data()\n",
    "\t\tself.test_data = test_loader.get_data()\n",
    "\n",
    "\t\t\n",
    "\tdef train(self,seed,svPath):\n",
    "\t\tbest_srcc = 0.0\n",
    "\t\tbest_plcc = 0.0\n",
    "\t\tprint('Epoch\\tTrain_Loss\\tTrain_SRCC\\tTest_SRCC\\tTest_PLCC\\tLearning_Rate\\tdroplr')\n",
    "\t\tsteps = 0\n",
    "\t\tresults = {}\n",
    "\t\tperformPath = svPath +'/' + 'PLCC_SRCC_'+str(self.config.vesion)+'_'+str(seed)+'.json'\n",
    "\t\twith open(performPath, 'w') as json_file2:\n",
    "\t\t\tjson.dump(  {} , json_file2)\n",
    "\n",
    "\t\t\n",
    "\t\t# self.testStep(self.net,self.test_data,'cuda')\n",
    "\t\t\n",
    "\t\tfor epochnum in range(self.epochs):\n",
    "\t\t\tself.net.train()\n",
    "\t\t\tepoch_loss = []\n",
    "\t\t\tpred_scores = []\n",
    "\t\t\tgt_scores = []\n",
    "\t\t\tpbar = tqdm(self.train_data, leave=False)\n",
    "\n",
    "\t\t\tfor img, label in pbar:\n",
    "\t\t\t\timg = torch.as_tensor(img.to(self.device)).requires_grad_(False)\n",
    "\t\t\t\tlabel = torch.as_tensor(label.to(self.device)).requires_grad_(False)\n",
    "\n",
    "\t\t\t\tsteps+=1\n",
    "\t\t\t\t\n",
    "\t\t\t\tself.net.zero_grad()\n",
    "\n",
    "\t\t\t\tpred,closs = self.net(img)\n",
    "\t\t\t\t# pred2,closs2 = self.net(torch.flip(img, [3]))  \n",
    "\n",
    "\t\t\t\tpred_scores = pred_scores + pred.flatten().cpu().tolist()\n",
    "\t\t\t\tgt_scores = gt_scores + label.cpu().tolist()\n",
    "\n",
    "\t\t\t\tloss_qa = self.l1_loss(pred.squeeze(), label.float().detach())\n",
    "\t\t\t\t# loss_qa2 = self.l1_loss(pred2.squeeze(), label.float().detach())\n",
    "\t\t\t\t# =============================================================================\n",
    "\t\t\t\t# =============================================================================\n",
    "\n",
    "\t\t\t\t# indexlabel = torch.argsort(label) # small--> large\n",
    "\t\t\t\t# # print(\"len \", len(indexlabel))\n",
    "\t\t\t\t# anchor1 = torch.unsqueeze(pred[indexlabel[0],...].contiguous(),dim=0) # d_min\n",
    "\t\t\t\t# positive1 = torch.unsqueeze(pred[indexlabel[1],...].contiguous(),dim=0) # d'_min+\n",
    "\t\t\t\t# negative1_1 = torch.unsqueeze(pred[indexlabel[-1],...].contiguous(),dim=0) # d_max+\n",
    "\n",
    "\t\t\t\t# anchor2 = torch.unsqueeze(pred[indexlabel[-1],...].contiguous(),dim=0)# d_max\n",
    "\t\t\t\t# positive2 = torch.unsqueeze(pred[indexlabel[-2],...].contiguous(),dim=0)# d'_max+\n",
    "\t\t\t\t# negative2_1 = torch.unsqueeze(pred[indexlabel[0],...].contiguous(),dim=0)# d_min+\n",
    "\n",
    "\t\t\t\t# # =============================================================================\n",
    "\t\t\t\t# # =============================================================================\n",
    "\n",
    "\t\t\t\t# fanchor1 = torch.unsqueeze(pred2[indexlabel[0],...].contiguous(),dim=0)\n",
    "\t\t\t\t# fpositive1 = torch.unsqueeze(pred2[indexlabel[1],...].contiguous(),dim=0)\n",
    "\t\t\t\t# fnegative1_1 = torch.unsqueeze(pred2[indexlabel[-1],...].contiguous(),dim=0)\n",
    "\n",
    "\t\t\t\t# fanchor2 = torch.unsqueeze(pred2[indexlabel[-1],...].contiguous(),dim=0)\n",
    "\t\t\t\t# fpositive2 = torch.unsqueeze(pred2[indexlabel[-2],...].contiguous(),dim=0)\n",
    "\t\t\t\t# fnegative2_1 = torch.unsqueeze(pred2[indexlabel[0],...].contiguous(),dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\t\t\t\t# consistency = nn.L1Loss()\n",
    "\t\t\t\t# assert (label[indexlabel[-1]]-label[indexlabel[1]])>=0\n",
    "\t\t\t\t# assert (label[indexlabel[-2]]-label[indexlabel[0]])>=0\n",
    "\t\t\t\t# triplet_loss1 = nn.TripletMarginLoss(margin=(label[indexlabel[-1]]-label[indexlabel[1]]), p=1) # d_min,d'_min,d_max\n",
    "\t\t\t\t# # triplet_loss2 = nn.TripletMarginLoss(margin=label[indexlabel[0]], p=1)\n",
    "\t\t\t\t# triplet_loss2 = nn.TripletMarginLoss(margin=(label[indexlabel[-2]]-label[indexlabel[0]]), p=1)\n",
    "\t\t\t\t# # triplet_loss1 = nn.TripletMarginLoss(margin=label[indexlabel[-1]], p=1)\n",
    "\t\t\t\t# # triplet_loss2 = nn.TripletMarginLoss(margin=label[indexlabel[0]], p=1)\n",
    "\t\t\t\t# tripletlosses = triplet_loss1(anchor1, positive1, negative1_1) + \\\n",
    "\t\t\t\t# \ttriplet_loss2(anchor2, positive2, negative2_1)\n",
    "\t\t\t\t# ftripletlosses = triplet_loss1(fanchor1, fpositive1, fnegative1_1) + \\\n",
    "\t\t\t\t# \ttriplet_loss2(fanchor2, fpositive2, fnegative2_1)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# loss = loss_qa + closs + loss_qa2 + closs2 + 0.5*( self.l1_loss(tripletlosses,ftripletlosses.detach())+ self.l1_loss(ftripletlosses,tripletlosses.detach()))+0.05*(tripletlosses+ftripletlosses)\n",
    "\t\t\t\t# loss = loss_qa + loss_qa2\n",
    "\t\t\t\tloss = loss_qa \n",
    "\t\t\t\t\n",
    "\t\t\t\tepoch_loss.append(loss.item())\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\tself.solver.step()\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\n",
    "\t\t\tmodelPath = svPath + '/model_{}_{}_{}'.format(str(self.config.vesion),str(seed),epochnum)\n",
    "\t\t\ttorch.save(self.net.state_dict(), modelPath)\n",
    "\n",
    "\t\t\ttrain_srcc, _ = stats.spearmanr(pred_scores, gt_scores)\n",
    "\n",
    "\t\t\ttest_srcc, test_plcc = self.test(self.test_data,epochnum,svPath,seed)\n",
    "\n",
    "\t\t\tself.testStep(self.net,self.test_data,'cuda')\n",
    "\n",
    "\n",
    "\t\t\tresults[epochnum]=(test_srcc, test_plcc)\n",
    "\t\t\twith open(performPath, \"r+\") as file:\n",
    "\t\t\t\tdata = json.load(file)\n",
    "\t\t\t\tdata.update(results)\n",
    "\t\t\t\tfile.seek(0)\n",
    "\t\t\t\tjson.dump(data, file)\n",
    "\t\t\t\n",
    "\n",
    "\t\t\n",
    "\t\t\tif test_srcc > best_srcc:\n",
    "\t\t\t\tmodelPathbest = svPath + '/bestmodel_{}_{}'.format(str(self.config.vesion),str(seed))\n",
    "\t\t\t\t\n",
    "\t\t\t\ttorch.save(self.net.state_dict(), modelPathbest)\n",
    "\n",
    "\t\t\t\tbest_srcc = test_srcc\n",
    "\t\t\t\tbest_plcc = test_plcc\n",
    "\n",
    "\t\t\tprint('{}\\t{:4.3f}\\t\\t{:4.4f}\\t\\t{:4.4f}\\t\\t{:4.3f}\\t\\t{}\\t\\t{:4.3f}'.format(epochnum + 1, sum(epoch_loss) / len(epoch_loss), train_srcc, test_srcc, test_plcc,self.paras[0]['lr'],self.droplr ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\t\tif (epochnum+1)==self.droplr or (epochnum+1)==(2*self.droplr) or (epochnum+1)==(3*self.droplr):\n",
    "\n",
    "\t\t\t\tself.lr = self.lr /self.lrratio\n",
    "\t\t\t\t\n",
    "\t\t\t\tself.paras = [{'params': self.net.parameters(), 'lr': self.lr} ]\n",
    "\t\t\t\t\n",
    "\t\t\t\tself.solver = torch.optim.Adam(self.paras, weight_decay=self.weight_decay)\n",
    "\n",
    "\t\tprint('Best test SRCC %f, PLCC %f' % (best_srcc, best_plcc))\n",
    "\n",
    "\t\treturn best_srcc, best_plcc\n",
    "\n",
    "\tdef test(self, data,epochnum,svPath,seed,pretrained=0):\n",
    "\t\tif pretrained:\n",
    "\t\t\tself.net.load_state_dict(torch.load(svPath+'/bestmodel_{}_{}'.format(str(self.config.vesion),str(seed))))\n",
    "\t\tself.net.eval()\n",
    "\t\tpred_scores = []\n",
    "\t\tgt_scores = []\n",
    "\t\t\n",
    "\t\tpbartest = tqdm(data, leave=False)\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tsteps2 = 0\n",
    "\t\t\n",
    "\t\t\t\n",
    "\t\n",
    "\t\t\tfor img, label in pbartest:\n",
    "\t\t\t\timg = torch.as_tensor(img.to(self.device))\n",
    "\t\t\t\tlabel = torch.as_tensor(label.to(self.device))\n",
    "\t\t\t\tpred,_ = self.net(img)\n",
    "\t\t\t\t\n",
    "\t\n",
    "\t\t\t\tpred_scores = pred_scores + pred.cpu().tolist()\n",
    "\t\t\t\tgt_scores = gt_scores + label.cpu().tolist()\n",
    "\t\t\t\t\n",
    "\t\t\t\tsteps2 += 1\n",
    "\t\t\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t# print(\"1\",pred_scores)\n",
    "\t\t# print(\"2\",np.array(pred_scores))\n",
    "\t\t# print(\"3\",np.reshape(np.array(pred_scores), (-1, self.test_patch_num)))\n",
    "\t\tpred_scores = np.mean(np.reshape(np.array(pred_scores), (-1, self.test_patch_num)), axis=1)\n",
    "\t\tgt_scores = np.mean(np.reshape(np.array(gt_scores), (-1, self.test_patch_num)), axis=1)\n",
    "\t\t\n",
    "\t\t# print(\"4\",pred_scores)\n",
    "\n",
    "# \t\tif not pretrained:\n",
    "\t\tdataPath = svPath + '/test_prediction_gt_{}_{}_{}.csv'.format(str(self.config.vesion),str(seed),epochnum)\n",
    "\t\twith open(dataPath, 'w') as f:\n",
    "\t\t\twriter = csv.writer(f)\n",
    "\t\t\twriter.writerows(zip(pred_scores, gt_scores))\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\ttest_srcc, _ = stats.spearmanr(pred_scores, gt_scores)\n",
    "\t\ttest_plcc, _ = stats.pearsonr(pred_scores, gt_scores)\n",
    "\t\treturn test_srcc, test_plcc\n",
    "\t\n",
    "\tdef testStep(self,\n",
    "\t\t\t\tmodel: nn.Module,\n",
    "\t\t\t\tdataLoader: DataLoader,\n",
    "\t\t\t\tdevice = 'cpu'):\n",
    "\t\tmodel.eval()\n",
    "\n",
    "\t\ttargets = torch.zeros((0)).unsqueeze(1).cpu()\n",
    "\t\tpreds = torch.zeros((0)).unsqueeze(1).cpu()\n",
    "\n",
    "\n",
    "\t\toutput:torch.Tensor\n",
    "\n",
    "\t\twith torch.inference_mode():\n",
    "\t\t\tfor i, data in tqdm(enumerate(dataLoader)):\n",
    "\t\t\t\timage, label = data\n",
    "\t\t\t\timage = image.to(device)\n",
    "\t\t\t\tlabel:torch.Tensor = label.to(device)\n",
    "\n",
    "\t\t\t\toutput, _ = model(image)\n",
    "\t\t\t\t# output= model(image)\n",
    "\t\t\t\ttargets = torch.cat((targets, label.unsqueeze(0).detach().cpu()), dim=0)\n",
    "\t\t\t\tpreds = torch.cat((preds, output.detach().cpu()),dim=0)\n",
    "\n",
    "\t\t\t# print(preds.shape)\n",
    "\t\t\t# print(targets.shape)\n",
    "\t\t\t# print(preds)\n",
    "\t\t\t# print(targets)\n",
    "\n",
    "\t\t\t# print(\"t1\",preds)\n",
    "\t\t\tpreds = preds.flatten().view((232,-1)).mean(1)\n",
    "\t\t\ttargets = targets.flatten().view((232,-1)).mean(1)\n",
    "\t\t\t# print(\"t2\",preds)\n",
    "\t\t\tsrcc, _ = stats.spearmanr(preds, targets)\n",
    "\t\t\tplcc, _ = stats.pearsonr(preds, targets)\n",
    "\t\t\tprint(\n",
    "\t\t\tf'  Testing... '\n",
    "\t\t\tf'SRCC: {srcc:.4f}, '\n",
    "\t\t\tf'PLCC: {plcc:.4f}')\n",
    "\t\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6a1efbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7000, 1.5000],\n",
      "        [1.7000, 2.5000],\n",
      "        [2.7000, 3.5000]])\n",
      "tensor([1.1000, 2.1000, 3.1000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0.7,1.5,1.7,2.5,2.7,3.5])\n",
    "print(a.view(3,-1))\n",
    "print(a.view(3,-1).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b486272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SavePath = config.svpath\n",
    "svPath = SavePath+ config.dataset + '_' + str(config.vesion)+'_'+str(config.seed)+'/'+'sv'\n",
    "os.makedirs(svPath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12490965",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsTrainPath = svPath + '/' + 'train_index_'+str(config.vesion)+'_'+str(config.seed)+'.json'\n",
    "imgsTestPath = svPath + '/' + 'test_index_'+str(config.vesion)+'_'+str(config.seed)+'.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c42976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrpaw/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mrpaw/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (L2pooling_l1): L2pooling()\n",
      "  (L2pooling_l2): L2pooling()\n",
      "  (L2pooling_l3): L2pooling()\n",
      "  (L2pooling_l4): L2pooling()\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=3840, out_features=3840, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=3840, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=3840, bias=True)\n",
      "          (norm1): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (position_embedding): PositionEmbeddingSine()\n",
      "  (fc2): Linear(in_features=3840, out_features=2048, bias=True)\n",
      "  (fc): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  (ReLU): ReLU()\n",
      "  (avg7): AvgPool2d(kernel_size=(7, 7), stride=(7, 7), padding=0)\n",
      "  (avg8): AvgPool2d(kernel_size=(8, 8), stride=(8, 8), padding=0)\n",
      "  (avg4): AvgPool2d(kernel_size=(4, 4), stride=(4, 4), padding=0)\n",
      "  (avg2): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
      "  (drop2d): Dropout(p=0.1, inplace=False)\n",
      "  (consistency): L1Loss()\n",
      ")\n",
      "Epoch\tTrain_Loss\tTrain_SRCC\tTest_SRCC\tTest_PLCC\tLearning_Rate\tdroplr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t14.059\t\t0.8562\t\t0.8713\t\t0.887\t\t2e-05\t\t0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t8.163\t\t0.9519\t\t0.8626\t\t0.868\t\t2e-05\t\t0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m solver = TReS(config,device, svPath, folder_path[config.dataset], train_index, test_index,Net, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m srcc_computed, plcc_computed = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43msvPath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mTReS.train\u001b[39m\u001b[34m(self, seed, svPath)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mself\u001b[39m.net.zero_grad()\n\u001b[32m     81\u001b[39m pred,closs = \u001b[38;5;28mself\u001b[39m.net(img)\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m pred2,closs2 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[32m     84\u001b[39m pred_scores = pred_scores + pred.flatten().cpu().tolist()\n\u001b[32m     85\u001b[39m gt_scores = gt_scores + label.cpu().tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1767\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1765\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1767\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1778\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1776\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1777\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1780\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1781\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Python/PytorchTestRocm/magisterka/org/models.py:131\u001b[39m, in \u001b[36mNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \t\u001b[38;5;28mself\u001b[39m.pos_enc_1 = \u001b[38;5;28mself\u001b[39m.position_embedding(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdim_modelt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    132\u001b[39m \t\u001b[38;5;28mself\u001b[39m.pos_enc = \u001b[38;5;28mself\u001b[39m.pos_enc_1.repeat(x.shape[\u001b[32m0\u001b[39m],\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m    134\u001b[39m \tout,layer1,layer2,layer3,layer4 = \u001b[38;5;28mself\u001b[39m.model(x) \n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Memory access fault by GPU node-1 (Agent handle: 0x188c4000) on address 0x7bfacf01c000. Reason: Page not present or supervisor privilege.\n"
     ]
    }
   ],
   "source": [
    "solver = TReS(config,device, svPath, folder_path[config.dataset], train_index, test_index,Net, None)\n",
    "srcc_computed, plcc_computed = solver.train(config.seed,svPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2305d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tres(\n",
       "  (cnn): Resnet50Blocks(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (aAvgPool2d): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (aAvgPool2dL4): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (aAvgPool2dT): AdaptiveAvgPool1d(output_size=1)\n",
       "  (flatten): Flatten(start_dim=2, end_dim=3)\n",
       "  (transformer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (mhsa): MultiHeadSelfAttentionBlock(\n",
       "        (msa): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=3840, out_features=3840, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (layerNorm): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
       "        (poseEncode): PosSineEncoding()\n",
       "      )\n",
       "      (ffn): FeedForwardNetworkBlock(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=3840, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.5, inplace=False)\n",
       "          (3): Linear(in_features=64, out_features=3840, bias=True)\n",
       "          (4): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (layerNorm): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (mhsa): MultiHeadSelfAttentionBlock(\n",
       "        (msa): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=3840, out_features=3840, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (layerNorm): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
       "        (poseEncode): PosSineEncoding()\n",
       "      )\n",
       "      (ffn): FeedForwardNetworkBlock(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=3840, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.5, inplace=False)\n",
       "          (3): Linear(in_features=64, out_features=3840, bias=True)\n",
       "          (4): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (layerNorm): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (posEncode): PosSineEncoding()\n",
       "  (l2pool1): L2Pooling()\n",
       "  (l2pool2): L2Pooling()\n",
       "  (l2pool3): L2Pooling()\n",
       "  (l2pool4): L2Pooling()\n",
       "  (dropoutLayer): Dropout(p=0.1, inplace=False)\n",
       "  (fc_trans): Linear(in_features=3840, out_features=2048, bias=True)\n",
       "  (fc_last): Linear(in_features=4096, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tres.impl_at1 import Tres \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cf5ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc3dbf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tres3Out(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.myModel = Tres(0.5,True,0.5,False,False)\n",
    "        self.cuda()\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        pred, l4, _ = self.myModel.forward(x)\n",
    "        return pred, l4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffe31273",
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = Tres3Out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4763cd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7240"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cec6a4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tres3Out(\n",
      "  (myModel): Tres(\n",
      "    (cnn): Resnet50Blocks(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "    )\n",
      "    (aAvgPool2d): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (aAvgPool2dL4): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (aAvgPool2dT): AdaptiveAvgPool1d(output_size=1)\n",
      "    (flatten): Flatten(start_dim=2, end_dim=3)\n",
      "    (transformer): Sequential(\n",
      "      (0): TransformerBlock(\n",
      "        (mhsa): MultiHeadSelfAttentionBlock(\n",
      "          (msa): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=3840, out_features=3840, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (layerNorm): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
      "          (poseEncode): PosSineEncoding()\n",
      "        )\n",
      "        (ffn): FeedForwardNetworkBlock(\n",
      "          (ffn): Sequential(\n",
      "            (0): Linear(in_features=3840, out_features=64, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "            (3): Linear(in_features=64, out_features=3840, bias=True)\n",
      "            (4): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (layerNorm): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): TransformerBlock(\n",
      "        (mhsa): MultiHeadSelfAttentionBlock(\n",
      "          (msa): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=3840, out_features=3840, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (layerNorm): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
      "          (poseEncode): PosSineEncoding()\n",
      "        )\n",
      "        (ffn): FeedForwardNetworkBlock(\n",
      "          (ffn): Sequential(\n",
      "            (0): Linear(in_features=3840, out_features=64, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "            (3): Linear(in_features=64, out_features=3840, bias=True)\n",
      "            (4): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (layerNorm): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (posEncode): PosSineEncoding()\n",
      "    (l2pool1): L2Pooling()\n",
      "    (l2pool2): L2Pooling()\n",
      "    (l2pool3): L2Pooling()\n",
      "    (l2pool4): L2Pooling()\n",
      "    (dropoutLayer): Dropout(p=0.1, inplace=False)\n",
      "    (fc_trans): Linear(in_features=3840, out_features=2048, bias=True)\n",
      "    (fc_last): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch\tTrain_Loss\tTrain_SRCC\tTest_SRCC\tTest_PLCC\tLearning_Rate\tdroplr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t15.726\t\t0.8282\t\t0.8130\t\t0.836\t\t2e-05\t\t0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m solver = TReS(config,device, svPath, folder_path[config.dataset], train_index, test_index,Net, myModel)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m srcc_computed, plcc_computed = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43msvPath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 132\u001b[39m, in \u001b[36mTReS.train\u001b[39m\u001b[34m(self, seed, svPath)\u001b[39m\n\u001b[32m    129\u001b[39m \tloss = loss_qa + loss_qa2\n\u001b[32m    131\u001b[39m \tepoch_loss.append(loss.item())\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \t\u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \t\u001b[38;5;28mself\u001b[39m.solver.step()\n\u001b[32m    139\u001b[39m modelPath = svPath + \u001b[33m'\u001b[39m\u001b[33m/model_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.config.vesion),\u001b[38;5;28mstr\u001b[39m(seed),epochnum)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "solver = TReS(config,device, svPath, folder_path[config.dataset], train_index, test_index,Net, myModel)\n",
    "srcc_computed, plcc_computed = solver.train(config.seed,svPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66329dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrpaw/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mrpaw/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (L2pooling_l1): L2pooling()\n",
      "  (L2pooling_l2): L2pooling()\n",
      "  (L2pooling_l3): L2pooling()\n",
      "  (L2pooling_l4): L2pooling()\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=3840, out_features=3840, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=3840, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=3840, bias=True)\n",
      "          (norm1): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((3840,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (position_embedding): PositionEmbeddingSine()\n",
      "  (fc2): Linear(in_features=3840, out_features=2048, bias=True)\n",
      "  (fc): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  (ReLU): ReLU()\n",
      "  (avg7): AvgPool2d(kernel_size=(7, 7), stride=(7, 7), padding=0)\n",
      "  (avg8): AvgPool2d(kernel_size=(8, 8), stride=(8, 8), padding=0)\n",
      "  (avg4): AvgPool2d(kernel_size=(4, 4), stride=(4, 4), padding=0)\n",
      "  (avg2): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
      "  (drop2d): Dropout(p=0.1, inplace=False)\n",
      "  (consistency): L1Loss()\n",
      ")\n",
      "Epoch\tTrain_Loss\tTrain_SRCC\tTest_SRCC\tTest_PLCC\tLearning_Rate\tdroplr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t7.472\t\t0.8473\t\t0.8299\t\t0.862\t\t2e-05\t\t0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m solver = TReS(config,device, svPath, folder_path[config.dataset], train_index, test_index,Net, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m srcc_computed, plcc_computed = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43msvPath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mTReS.train\u001b[39m\u001b[34m(self, seed, svPath)\u001b[39m\n\u001b[32m     81\u001b[39m pred,closs = \u001b[38;5;28mself\u001b[39m.net(img)\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# pred2,closs2 = self.net(torch.flip(img, [3]))  \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m pred_scores = pred_scores + \u001b[43mpred\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.tolist()\n\u001b[32m     85\u001b[39m gt_scores = gt_scores + label.cpu().tolist()\n\u001b[32m     87\u001b[39m loss_qa = \u001b[38;5;28mself\u001b[39m.l1_loss(pred.squeeze(), label.float().detach())\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "solver = TReS(config,device, svPath, folder_path[config.dataset], train_index, test_index,Net, None)\n",
    "srcc_computed, plcc_computed = solver.train(config.seed,svPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e18a3c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x727ee3e4ce30>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "agr = []\n",
    "lbl: Tensor\n",
    "for img, lbl in trainDataLoader1:\n",
    "    agr.append(lbl.__array__())\n",
    "agr = np.array(agr).flatten()\n",
    "\n",
    "plt.scatter(np.arange(len(agr)), agr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cff4d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 2\n",
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d11ba9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del solver\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d62091c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Należy to ustawić na początku skryptu lub w funkcji `train`\n",
    "seed = 2137\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba644980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch\tTrain_Loss\tTrain_SRCC\tTest_SRCC\tTest_PLCC\tLearning_Rate\tdroplr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4640it [04:15, 18.19it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing... SRCC: 0.8329, PLCC: 0.8560\n",
      "1\t9.331\t\t0.7668\t\t0.8398\t\t0.862\t\t2e-05\t\t0.000\n",
      "Best test SRCC 0.839813, PLCC 0.862428\n"
     ]
    }
   ],
   "source": [
    "solver = TReS(config,device, svPath, folder_path[config.dataset], train_index, test_index,Net, None)\n",
    "srcc_computed, plcc_computed = solver.train(config.seed,svPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
